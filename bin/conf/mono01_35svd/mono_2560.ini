#
# Deep Neural Netwrok
# Version: 1.0 Created by bykim
# This is a generated file. Edit possible!
#
#	[Example]: input file for the estimation of DNN-HMM parameters
#	# Task Type
#	TASK_TYPE = Task type [train/svd/test]
#
#	# Structure Parameters
#	FEAT_DIM = Feature dimension
#	FRAME_CONCAT = # of Frame concatanated to both side of the reference frame (ex. if 10, total input frame number will be 21)
#	NUM_CLASS = # of class as well as # of output nodes
#	NUM_LAYER = # of total layer
#	NUM_HID_NODES = # of hidden nodes
#	NON_LINEAR_FUNC = Non linear function type at each layer [SIGMOID/RELU/SOFTMAX/LINEAR]
#			When it comes to "Softmax", it should always be placed final stage
#			When it comes to "Linear" and "ReLU", it should always NOT be placed final stage
#
#	# Training & Test Parameters
#	USE_FANINOUT_INIT = Do use option for fan-in fan-out initialize? [yes/no] (default = yes)
#	MOMENTUM_ALPHA = Momentum Coefficient (ex. 0.9)
#	DO_SHUFFLE = Do shuffle the data in frame level? [yes/no] (default = yes)
#	USE_DROPOUT = Do use dropout? [yes/no] (default = no)
#	ERR_CHK_LR_CHANGE_ITER = Check err and change learning rate period (ex. 10000)
#	LR = Learning rate  (ex. 2.0e-3)
#	LR_SUSTAIN_ITER = #of sustained learning rate iter
#	LR_REDUCE_RATIO = Learning rate reduce ratio
#	MIN_LR = Minimum learning rate
#	MAX_EPOCH = Maximum epoch
#	MINI_BATCH_SIZE = Mini batch size
#	USE_W_MAX_NORM = Do use weight max-norm regularization? (only GPU)
#	W_MAX_NORM_CONST = Max-norm constant value (only GPU)
#	USE_GRAD_CLASS_NORM = Do use class wise gradient normalization? (only GPU)
#	DATA_PATH = Train data path
#	TRAIN_LIST_FILE = Train list file (WITH extension)
#	LABEL_PATH = Target label path
#	LABEL_EXT = label extension
#	DNN_SAVE_FILE_NAME = Neural net save file name (WITHOUT extension)
#	DO_PRINT_TEST_RESULT_TO_CONSOLE = if yes, tested confusion matrix will be printed if no, will be not printed [yes/no] (default = no)
#	ERR_MEASURE_FUNC = Error measure function type [SQRERR/CROSS_ENTROPY]
#	USE_GPU = Do use GPU? [yes/no] (default = yes)
#	USE_SEED_DNN = Do use seed dnn?
#	SEED_DNN_FILE = Seed dnn file (WITH extension)
#	
#	# Log Paramenters
#	DEV_TEST_LIST = Development set list (WITH extension)
#	DEV_CONFMAT = Development set test results with confusion matrix (WITHOUT extension)
#	DEV_TOT_ERR_LOG = Development set test results with only total error (WITH extension)
#	VALI_TEST_LIST = Validation set list (WITH extension)
#	VALI_CONFMAT = Validation set test results with confusion matrix (WITHOUT extension)
#	VALI_TOT_ERR_LOG = Validation set test results with only total error (WITH extension)
#


# Task Type
TASK_TYPE = train

# Structure Parameters
FEAT_DIM = 51
#FRAME_CONCAT = 12

FRAME_CONCAT_BEFORE = 12
FRAME_CONCAT_AFTER = 12

NUM_CLASS = 35
NUM_LAYER = 9
NUM_HID_NODES = 2560-192-2560-192-2560-192-2560
NON_LINEAR_FUNC = RELU-LINEAR-RELU-LINEAR-RELU-LINEAR-RELU-SOFTMAX

# Training & Test Parameters
USE_FANINOUT_INIT = no
MOMENTUM_ALPHA = 0.9
DO_SHUFFLE = yes
USE_DROPOUT = no
ERR_CHK_LR_CHANGE_ITER = 50000
LR = 1.0e-5

LR_SUSTAIN_ITER = 60000
LR_REDUCE_RATIO = 0.998
MIN_LR = 5.0e-8
MAX_EPOCH = 10
MINI_BATCH_SIZE = 100
USE_W_MAX_NORM = yes
W_MAX_NORM_CONST = 4.0
USE_GRAD_CLASS_NORM = yes

DATA_PATH = F:/
TRAIN_LIST_FILE = F:/_total-cms_align_merged_shuffled.mfc.txt

LABEL_PATH = E:/_mono_phone_dnn_training/
LABEL_EXT = algt35
DNN_SAVE_FILE_NAME = 61model/deepnet

DO_PRINT_TEST_RESULT_TO_CONSOLE = no
ERR_MEASURE_FUNC = CROSS_ENTROPY
USE_GPU = yes

USE_SEED_DNN = yes
SEED_DNN_FILE = ../conf/mono01_35svd/deepnet_0_3674415.dat

USE_DIFF_OUTPUT_NODE_SEED_MODEL = no

# Log Paramenters
DEV_TEST_LIST = F:/_total-cms_align_merged_dev2000.mfc.txt
DEV_CONFMAT = 61log/log_dev
DEV_TOT_ERR_LOG = 61log/_log_err_dev.txt
VALI_TEST_LIST = F:/_total-cms_align_merged_vali2000.mfc.txt
VALI_CONFMAT = 61log/log_vali
VALI_TOT_ERR_LOG = 61log/_log_err_vali.txt
